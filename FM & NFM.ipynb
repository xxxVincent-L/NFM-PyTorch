{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "* FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(x, mean=0., std=1.):\n",
    "    return x.normal_().fmod_(2).mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, n, k):\n",
    "        super().__init__()\n",
    "        self.bias = nn.Embedding(n, 1)\n",
    "        self.embeddings = nn.Embedding(n, k)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            initialization(self.embeddings.weight, std=0.01)\n",
    "            initialization(self.bias.weight, std=0.01)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        dense_emb = self.embeddings(X)\n",
    "\n",
    "        p1 = dense_emb.sum(dim=1).pow(2)\n",
    "        p2 = dense_emb.pow(2).sum(dim=1)\n",
    "\n",
    "        interaction_layer = 0.5 * (p1-p2).sum(1)\n",
    "        linear_layer = self.bias(X).squeeze().sum(1)\n",
    "\n",
    "        return linear_layer + interaction_layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* BPR Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self, item1 = None, item2 = None):\n",
    "        super(BPRLoss, self).__init__()\n",
    "        self.item1 = item1\n",
    "        self.item2 = item2\n",
    "\n",
    "    def forward(self, item1, item2):\n",
    "        dist = item1 - item2\n",
    "        return -torch.sum(torch.log(sigmoid(dist)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens(Dataset):\n",
    "    def __init__(self, pair1, pair2):\n",
    "        self.pair1 = pair1\n",
    "        self.pair2 = pair2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pair1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p1 = self.pair1[idx]\n",
    "        p2 = self.pair2[idx]\n",
    "        return p1, p2\n",
    "\n",
    "\n",
    "def data_tensor(dataset):\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    user_feature = dataset.iloc[:,0:3]\n",
    "    movie1_feature = dataset.iloc[:,3:5]\n",
    "    movie2_feature = dataset.iloc[:,5:7]\n",
    "    \n",
    "    positive = user_feature.join(movie1_feature)\n",
    "    negative = user_feature.join(movie2_feature)\n",
    "\n",
    "    # positive = scaler.fit_transform(positive.values)\n",
    "    # positive = torch.tensor(positive).int()\n",
    "\n",
    "    # negative = scaler.fit_transform(negative.values)\n",
    "    # negative = torch.tensor(negative).int()\n",
    "    positive = torch.tensor(positive.values).int()\n",
    "    negative = torch.tensor(negative.values).int()\n",
    "\n",
    "    return MovieLens(positive, negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_set_path = {\"full\": '',\n",
    "                \"sampled\":\"./data/revised_bpr_sampled_train_set.csv\" }\n",
    "val_set_path = {\"full\": '',\n",
    "                \"sampled\":\"./data/revised_bpr_sampled_val_set.csv\" }\n",
    "\n",
    "\n",
    "train_set = pd.read_csv(train_set_path['sampled'], header=0)\n",
    "val_set = pd.read_csv(val_set_path['sampled'], header=0)\n",
    "\n",
    "\n",
    "train_set = data_tensor(train_set)\n",
    "val_set = data_tensor(val_set)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for pair1, pair2 in dataloader:\n",
    "        pair1, pair2 = pair1.to(device), pair2.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        score1, score2 = model(pair1), model(pair2)\n",
    "        loss = criterion(score1, score2)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss / len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader, criterion):\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    for pair1, pair2 in dataloader:\n",
    "        pair1, pair2 = pair1.to(device), pair2.to(device)\n",
    "        with torch.no_grad():\n",
    "            score1, score2 = model(pair1), model(pair2)\n",
    "        loss = criterion(score1, score2)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 10052\n",
    "num_dimention = 100\n",
    "model = FM(num_features,num_dimention)\n",
    "wd=1e-5\n",
    "lr=1e-4\n",
    "epochs=20\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4], gamma=0.1)\n",
    "criterion = BPRLoss()\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion)\n",
    "    val_loss = validation(model, val_dataloader, criterion)\n",
    "    scheduler.step()\n",
    "\n",
    "    sqrt_train_loss = (math.sqrt(train_loss))\n",
    "    sqrt_val_loss = (math.sqrt(val_loss))\n",
    "    \n",
    "    print(f'epoch {epoch}:')\n",
    "    print(f'\\ttrain loss: {train_loss:.4f}')\n",
    "    print(f'\\tvalidation loss: {val_loss:.4f}')\n",
    "    if epoch % 5 == 0:\n",
    "      file_name = './model/model_'+str(epoch)+'.pth'\n",
    "      torch.save(model.state_dict(), file_name)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#plot 1:\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training')\n",
    "\n",
    "#plot 2:\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), val_loss_list)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './model/model_v6.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
